{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 中级教程1：卷积神经网络（CNN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 硬件配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch one data pair (read data from disk).\n",
    "image, label = train_dataset[0]\n",
    "print (image.size())\n",
    "print (label)\n",
    "\n",
    "# 显示图片\n",
    "def show_image(image, label):\n",
    "    # Convert the tensor image to a numpy array and transpose the dimensions\n",
    "    tmp_image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(tmp_image)\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.show()\n",
    "    \n",
    "show_image(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型：CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数、优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.1049\n",
      "Epoch [1/5], Step [200/600], Loss: 0.0699\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1166\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0917\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0519\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0688\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0058\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0270\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0398\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0497\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0120\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0881\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0174\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0271\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0043\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0372\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0160\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0161\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0107\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0096\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0269\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0430\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0886\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0375\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0470\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0013\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0068\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0056\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0315\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0100\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98.72 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
