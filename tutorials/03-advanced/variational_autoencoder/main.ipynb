{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 高级教程2：变分自编码器（VAE）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 硬件配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory if not exists\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "    \n",
    "# MNIST dataset\n",
    "dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "                                     train=True,\n",
    "                                     transform=transforms.ToTensor(),\n",
    "                                     download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型：VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "\n",
    "model = VAE().to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\envs\\pytorch-tutorial\\lib\\site-packages\\torch\\nn\\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "d:\\ProgramData\\anaconda3\\envs\\pytorch-tutorial\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [10/469], Reconst Loss: 36826.0195, KL Div: 2827.7910\n",
      "Epoch[1/15], Step [20/469], Reconst Loss: 29603.6289, KL Div: 1227.5696\n",
      "Epoch[1/15], Step [30/469], Reconst Loss: 27758.5195, KL Div: 1150.4274\n",
      "Epoch[1/15], Step [40/469], Reconst Loss: 27148.9707, KL Div: 635.3127\n",
      "Epoch[1/15], Step [50/469], Reconst Loss: 27245.4121, KL Div: 614.3327\n",
      "Epoch[1/15], Step [60/469], Reconst Loss: 25424.0469, KL Div: 746.2432\n",
      "Epoch[1/15], Step [70/469], Reconst Loss: 24993.3359, KL Div: 862.5182\n",
      "Epoch[1/15], Step [80/469], Reconst Loss: 24438.9473, KL Div: 1093.7292\n",
      "Epoch[1/15], Step [90/469], Reconst Loss: 23707.3750, KL Div: 1179.3423\n",
      "Epoch[1/15], Step [100/469], Reconst Loss: 23581.5391, KL Div: 1333.9926\n",
      "Epoch[1/15], Step [110/469], Reconst Loss: 20800.9629, KL Div: 1462.1167\n",
      "Epoch[1/15], Step [120/469], Reconst Loss: 20831.3105, KL Div: 1697.3671\n",
      "Epoch[1/15], Step [130/469], Reconst Loss: 19694.0352, KL Div: 1729.7761\n",
      "Epoch[1/15], Step [140/469], Reconst Loss: 19251.8789, KL Div: 1867.1626\n",
      "Epoch[1/15], Step [150/469], Reconst Loss: 18500.7422, KL Div: 1819.6384\n",
      "Epoch[1/15], Step [160/469], Reconst Loss: 19167.4531, KL Div: 1746.0865\n",
      "Epoch[1/15], Step [170/469], Reconst Loss: 18524.7109, KL Div: 2020.9407\n",
      "Epoch[1/15], Step [180/469], Reconst Loss: 17764.9355, KL Div: 1883.8785\n",
      "Epoch[1/15], Step [190/469], Reconst Loss: 17670.1113, KL Div: 1932.6511\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 17940.5859, KL Div: 1966.8325\n",
      "Epoch[1/15], Step [210/469], Reconst Loss: 16759.4805, KL Div: 1975.5513\n",
      "Epoch[1/15], Step [220/469], Reconst Loss: 17220.2969, KL Div: 2024.6910\n",
      "Epoch[1/15], Step [230/469], Reconst Loss: 16800.2520, KL Div: 2108.4912\n",
      "Epoch[1/15], Step [240/469], Reconst Loss: 16757.0820, KL Div: 2211.4607\n",
      "Epoch[1/15], Step [250/469], Reconst Loss: 16527.2148, KL Div: 2218.8711\n",
      "Epoch[1/15], Step [260/469], Reconst Loss: 16177.4883, KL Div: 2115.2988\n",
      "Epoch[1/15], Step [270/469], Reconst Loss: 16036.6074, KL Div: 2384.4731\n",
      "Epoch[1/15], Step [280/469], Reconst Loss: 16604.5410, KL Div: 2309.8293\n",
      "Epoch[1/15], Step [290/469], Reconst Loss: 15701.4229, KL Div: 2306.3706\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 15509.2852, KL Div: 2402.3533\n",
      "Epoch[1/15], Step [310/469], Reconst Loss: 15891.9844, KL Div: 2338.3066\n",
      "Epoch[1/15], Step [320/469], Reconst Loss: 14671.9043, KL Div: 2545.3550\n",
      "Epoch[1/15], Step [330/469], Reconst Loss: 15188.6445, KL Div: 2412.6287\n",
      "Epoch[1/15], Step [340/469], Reconst Loss: 15214.0215, KL Div: 2573.3494\n",
      "Epoch[1/15], Step [350/469], Reconst Loss: 15412.0781, KL Div: 2443.6597\n",
      "Epoch[1/15], Step [360/469], Reconst Loss: 14663.6816, KL Div: 2498.8708\n",
      "Epoch[1/15], Step [370/469], Reconst Loss: 14824.0791, KL Div: 2322.3237\n",
      "Epoch[1/15], Step [380/469], Reconst Loss: 13584.3789, KL Div: 2528.8677\n",
      "Epoch[1/15], Step [390/469], Reconst Loss: 14235.6953, KL Div: 2458.8801\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 14268.0322, KL Div: 2608.2002\n",
      "Epoch[1/15], Step [410/469], Reconst Loss: 14632.7119, KL Div: 2587.6631\n",
      "Epoch[1/15], Step [420/469], Reconst Loss: 14895.6855, KL Div: 2696.7935\n",
      "Epoch[1/15], Step [430/469], Reconst Loss: 14150.1133, KL Div: 2593.0684\n",
      "Epoch[1/15], Step [440/469], Reconst Loss: 14376.1719, KL Div: 2660.9517\n",
      "Epoch[1/15], Step [450/469], Reconst Loss: 14602.4482, KL Div: 2614.3438\n",
      "Epoch[1/15], Step [460/469], Reconst Loss: 13670.4316, KL Div: 2680.8770\n",
      "Epoch[2/15], Step [10/469], Reconst Loss: 14122.0303, KL Div: 2576.3259\n",
      "Epoch[2/15], Step [20/469], Reconst Loss: 13348.4512, KL Div: 2699.7144\n",
      "Epoch[2/15], Step [30/469], Reconst Loss: 13458.7051, KL Div: 2660.5688\n",
      "Epoch[2/15], Step [40/469], Reconst Loss: 13654.9873, KL Div: 2679.1753\n",
      "Epoch[2/15], Step [50/469], Reconst Loss: 13304.9209, KL Div: 2811.8003\n",
      "Epoch[2/15], Step [60/469], Reconst Loss: 14078.9990, KL Div: 2592.8149\n",
      "Epoch[2/15], Step [70/469], Reconst Loss: 13030.1289, KL Div: 2799.6074\n",
      "Epoch[2/15], Step [80/469], Reconst Loss: 13102.1250, KL Div: 2780.2949\n",
      "Epoch[2/15], Step [90/469], Reconst Loss: 13145.0488, KL Div: 2733.0212\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 13715.2207, KL Div: 2851.3542\n",
      "Epoch[2/15], Step [110/469], Reconst Loss: 13039.7676, KL Div: 2761.9753\n",
      "Epoch[2/15], Step [120/469], Reconst Loss: 13172.9287, KL Div: 2809.7656\n",
      "Epoch[2/15], Step [130/469], Reconst Loss: 13064.4785, KL Div: 2885.8328\n",
      "Epoch[2/15], Step [140/469], Reconst Loss: 13028.4746, KL Div: 2830.7969\n",
      "Epoch[2/15], Step [150/469], Reconst Loss: 12998.3252, KL Div: 2847.7461\n",
      "Epoch[2/15], Step [160/469], Reconst Loss: 13023.6562, KL Div: 2860.4648\n",
      "Epoch[2/15], Step [170/469], Reconst Loss: 12832.6240, KL Div: 2826.8140\n",
      "Epoch[2/15], Step [180/469], Reconst Loss: 12701.2031, KL Div: 3042.7007\n",
      "Epoch[2/15], Step [190/469], Reconst Loss: 13193.0518, KL Div: 2877.4746\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 12593.2520, KL Div: 2862.8718\n",
      "Epoch[2/15], Step [210/469], Reconst Loss: 12708.4141, KL Div: 2899.6826\n",
      "Epoch[2/15], Step [220/469], Reconst Loss: 12695.4824, KL Div: 2798.1531\n",
      "Epoch[2/15], Step [230/469], Reconst Loss: 12296.4883, KL Div: 2974.9004\n",
      "Epoch[2/15], Step [240/469], Reconst Loss: 12389.8105, KL Div: 2872.8574\n",
      "Epoch[2/15], Step [250/469], Reconst Loss: 12477.7510, KL Div: 3008.9736\n",
      "Epoch[2/15], Step [260/469], Reconst Loss: 12113.4336, KL Div: 2854.2686\n",
      "Epoch[2/15], Step [270/469], Reconst Loss: 12732.9277, KL Div: 2914.7134\n",
      "Epoch[2/15], Step [280/469], Reconst Loss: 12649.6172, KL Div: 2976.7065\n",
      "Epoch[2/15], Step [290/469], Reconst Loss: 12436.8555, KL Div: 2862.6536\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 11788.2139, KL Div: 2826.1699\n",
      "Epoch[2/15], Step [310/469], Reconst Loss: 12886.4902, KL Div: 2917.4797\n",
      "Epoch[2/15], Step [320/469], Reconst Loss: 11752.0732, KL Div: 2825.2280\n",
      "Epoch[2/15], Step [330/469], Reconst Loss: 12407.5107, KL Div: 3014.1274\n",
      "Epoch[2/15], Step [340/469], Reconst Loss: 12061.5605, KL Div: 2864.3140\n",
      "Epoch[2/15], Step [350/469], Reconst Loss: 12477.1318, KL Div: 2931.5942\n",
      "Epoch[2/15], Step [360/469], Reconst Loss: 11921.2715, KL Div: 2965.4724\n",
      "Epoch[2/15], Step [370/469], Reconst Loss: 12017.0664, KL Div: 2890.1868\n",
      "Epoch[2/15], Step [380/469], Reconst Loss: 11730.4980, KL Div: 2996.5059\n",
      "Epoch[2/15], Step [390/469], Reconst Loss: 12325.0010, KL Div: 2890.6943\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 11940.0127, KL Div: 2897.4062\n",
      "Epoch[2/15], Step [410/469], Reconst Loss: 12281.1992, KL Div: 3050.4233\n",
      "Epoch[2/15], Step [420/469], Reconst Loss: 12487.1865, KL Div: 3023.4224\n",
      "Epoch[2/15], Step [430/469], Reconst Loss: 12577.9385, KL Div: 3107.6582\n",
      "Epoch[2/15], Step [440/469], Reconst Loss: 12248.6377, KL Div: 2988.1499\n",
      "Epoch[2/15], Step [450/469], Reconst Loss: 12550.2207, KL Div: 3058.0725\n",
      "Epoch[2/15], Step [460/469], Reconst Loss: 11894.3789, KL Div: 3003.8960\n",
      "Epoch[3/15], Step [10/469], Reconst Loss: 11749.1758, KL Div: 3009.0352\n",
      "Epoch[3/15], Step [20/469], Reconst Loss: 12212.0020, KL Div: 3032.8044\n",
      "Epoch[3/15], Step [30/469], Reconst Loss: 11608.8721, KL Div: 3177.3472\n",
      "Epoch[3/15], Step [40/469], Reconst Loss: 11709.8799, KL Div: 2993.2522\n",
      "Epoch[3/15], Step [50/469], Reconst Loss: 11746.6055, KL Div: 3035.2871\n",
      "Epoch[3/15], Step [60/469], Reconst Loss: 11975.5488, KL Div: 2967.5293\n",
      "Epoch[3/15], Step [70/469], Reconst Loss: 12022.7676, KL Div: 2996.8069\n",
      "Epoch[3/15], Step [80/469], Reconst Loss: 12171.2705, KL Div: 3122.3838\n",
      "Epoch[3/15], Step [90/469], Reconst Loss: 11514.7598, KL Div: 3141.9854\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 11941.0449, KL Div: 2955.2046\n",
      "Epoch[3/15], Step [110/469], Reconst Loss: 11681.6523, KL Div: 3142.7043\n",
      "Epoch[3/15], Step [120/469], Reconst Loss: 11699.7188, KL Div: 2996.5413\n",
      "Epoch[3/15], Step [130/469], Reconst Loss: 12015.2412, KL Div: 3084.4353\n",
      "Epoch[3/15], Step [140/469], Reconst Loss: 11689.6143, KL Div: 3046.3169\n",
      "Epoch[3/15], Step [150/469], Reconst Loss: 11508.1875, KL Div: 3105.3999\n",
      "Epoch[3/15], Step [160/469], Reconst Loss: 11783.3184, KL Div: 2960.9192\n",
      "Epoch[3/15], Step [170/469], Reconst Loss: 11648.5645, KL Div: 3065.8623\n",
      "Epoch[3/15], Step [180/469], Reconst Loss: 11415.5742, KL Div: 3163.8164\n",
      "Epoch[3/15], Step [190/469], Reconst Loss: 11597.9746, KL Div: 3061.7715\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 11532.1182, KL Div: 3005.6472\n",
      "Epoch[3/15], Step [210/469], Reconst Loss: 11456.1318, KL Div: 3097.9536\n",
      "Epoch[3/15], Step [220/469], Reconst Loss: 11530.4492, KL Div: 3076.0635\n",
      "Epoch[3/15], Step [230/469], Reconst Loss: 11855.3203, KL Div: 3231.8855\n",
      "Epoch[3/15], Step [240/469], Reconst Loss: 11428.7734, KL Div: 2915.1973\n",
      "Epoch[3/15], Step [250/469], Reconst Loss: 11691.5322, KL Div: 3258.1589\n",
      "Epoch[3/15], Step [260/469], Reconst Loss: 11976.8340, KL Div: 3062.6672\n",
      "Epoch[3/15], Step [270/469], Reconst Loss: 11319.0488, KL Div: 3107.6404\n",
      "Epoch[3/15], Step [280/469], Reconst Loss: 11611.0078, KL Div: 3134.5945\n",
      "Epoch[3/15], Step [290/469], Reconst Loss: 11382.5693, KL Div: 2958.0483\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 11723.6777, KL Div: 3197.5562\n",
      "Epoch[3/15], Step [310/469], Reconst Loss: 11352.8594, KL Div: 3053.1069\n",
      "Epoch[3/15], Step [320/469], Reconst Loss: 11089.9746, KL Div: 3138.9832\n",
      "Epoch[3/15], Step [330/469], Reconst Loss: 11515.2979, KL Div: 2970.8821\n",
      "Epoch[3/15], Step [340/469], Reconst Loss: 11902.9395, KL Div: 3226.1123\n",
      "Epoch[3/15], Step [350/469], Reconst Loss: 11435.9463, KL Div: 3181.0164\n",
      "Epoch[3/15], Step [360/469], Reconst Loss: 11157.3672, KL Div: 3074.7026\n",
      "Epoch[3/15], Step [370/469], Reconst Loss: 11552.1943, KL Div: 3088.1633\n",
      "Epoch[3/15], Step [380/469], Reconst Loss: 11301.9229, KL Div: 3242.5405\n",
      "Epoch[3/15], Step [390/469], Reconst Loss: 11535.2598, KL Div: 3089.9951\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 10804.5996, KL Div: 2980.1040\n",
      "Epoch[3/15], Step [410/469], Reconst Loss: 11980.1445, KL Div: 3180.1377\n",
      "Epoch[3/15], Step [420/469], Reconst Loss: 11357.4434, KL Div: 3052.0383\n",
      "Epoch[3/15], Step [430/469], Reconst Loss: 11358.6660, KL Div: 3095.9604\n",
      "Epoch[3/15], Step [440/469], Reconst Loss: 11470.0625, KL Div: 3193.4126\n",
      "Epoch[3/15], Step [450/469], Reconst Loss: 11586.7080, KL Div: 3085.2205\n",
      "Epoch[3/15], Step [460/469], Reconst Loss: 11028.3652, KL Div: 3042.3298\n",
      "Epoch[4/15], Step [10/469], Reconst Loss: 10995.8809, KL Div: 3034.6304\n",
      "Epoch[4/15], Step [20/469], Reconst Loss: 11533.8125, KL Div: 3127.3999\n",
      "Epoch[4/15], Step [30/469], Reconst Loss: 11117.7402, KL Div: 3139.7515\n",
      "Epoch[4/15], Step [40/469], Reconst Loss: 11395.2207, KL Div: 3152.8198\n",
      "Epoch[4/15], Step [50/469], Reconst Loss: 11493.1973, KL Div: 3196.1147\n",
      "Epoch[4/15], Step [60/469], Reconst Loss: 10842.8535, KL Div: 3076.8604\n",
      "Epoch[4/15], Step [70/469], Reconst Loss: 11549.3408, KL Div: 3175.9434\n",
      "Epoch[4/15], Step [80/469], Reconst Loss: 11280.2891, KL Div: 3142.5942\n",
      "Epoch[4/15], Step [90/469], Reconst Loss: 11365.3633, KL Div: 3143.7573\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 10971.8965, KL Div: 3158.2605\n",
      "Epoch[4/15], Step [110/469], Reconst Loss: 11338.8496, KL Div: 3101.4734\n",
      "Epoch[4/15], Step [120/469], Reconst Loss: 11243.1719, KL Div: 3163.0596\n",
      "Epoch[4/15], Step [130/469], Reconst Loss: 11258.9043, KL Div: 3073.4929\n",
      "Epoch[4/15], Step [140/469], Reconst Loss: 10972.0664, KL Div: 3208.9121\n",
      "Epoch[4/15], Step [150/469], Reconst Loss: 11390.3652, KL Div: 3112.4973\n",
      "Epoch[4/15], Step [160/469], Reconst Loss: 11101.1982, KL Div: 3145.6411\n",
      "Epoch[4/15], Step [170/469], Reconst Loss: 11604.2578, KL Div: 3214.3711\n",
      "Epoch[4/15], Step [180/469], Reconst Loss: 11402.9434, KL Div: 3080.8596\n",
      "Epoch[4/15], Step [190/469], Reconst Loss: 11312.7783, KL Div: 3290.0264\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 10903.4238, KL Div: 3063.5603\n",
      "Epoch[4/15], Step [210/469], Reconst Loss: 11031.9170, KL Div: 3079.7771\n",
      "Epoch[4/15], Step [220/469], Reconst Loss: 11316.4736, KL Div: 3195.0564\n",
      "Epoch[4/15], Step [230/469], Reconst Loss: 11023.9482, KL Div: 3278.2612\n",
      "Epoch[4/15], Step [240/469], Reconst Loss: 10484.4932, KL Div: 3077.0154\n",
      "Epoch[4/15], Step [250/469], Reconst Loss: 11184.4902, KL Div: 3245.9351\n",
      "Epoch[4/15], Step [260/469], Reconst Loss: 11206.9082, KL Div: 3141.2773\n",
      "Epoch[4/15], Step [270/469], Reconst Loss: 11267.0498, KL Div: 3173.6951\n",
      "Epoch[4/15], Step [280/469], Reconst Loss: 10927.0303, KL Div: 3139.1013\n",
      "Epoch[4/15], Step [290/469], Reconst Loss: 10938.5840, KL Div: 3100.5806\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 11096.0664, KL Div: 3145.0581\n",
      "Epoch[4/15], Step [310/469], Reconst Loss: 11423.6348, KL Div: 3145.6128\n",
      "Epoch[4/15], Step [320/469], Reconst Loss: 11295.7861, KL Div: 3158.7466\n",
      "Epoch[4/15], Step [330/469], Reconst Loss: 11465.6631, KL Div: 3106.9229\n",
      "Epoch[4/15], Step [340/469], Reconst Loss: 11196.8672, KL Div: 3197.2925\n",
      "Epoch[4/15], Step [350/469], Reconst Loss: 10902.9912, KL Div: 3254.2920\n",
      "Epoch[4/15], Step [360/469], Reconst Loss: 10938.8203, KL Div: 3190.9182\n",
      "Epoch[4/15], Step [370/469], Reconst Loss: 10936.9854, KL Div: 3078.8362\n",
      "Epoch[4/15], Step [380/469], Reconst Loss: 11145.2432, KL Div: 3160.6057\n",
      "Epoch[4/15], Step [390/469], Reconst Loss: 10876.8926, KL Div: 3224.0449\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 10809.9971, KL Div: 3086.9939\n",
      "Epoch[4/15], Step [410/469], Reconst Loss: 11040.3789, KL Div: 3106.7891\n",
      "Epoch[4/15], Step [420/469], Reconst Loss: 11183.3066, KL Div: 3150.2458\n",
      "Epoch[4/15], Step [430/469], Reconst Loss: 10806.2080, KL Div: 3098.7834\n",
      "Epoch[4/15], Step [440/469], Reconst Loss: 11123.5889, KL Div: 3173.1060\n",
      "Epoch[4/15], Step [450/469], Reconst Loss: 10690.4883, KL Div: 3164.6138\n",
      "Epoch[4/15], Step [460/469], Reconst Loss: 11010.5742, KL Div: 3104.7944\n",
      "Epoch[5/15], Step [10/469], Reconst Loss: 10703.0742, KL Div: 3184.9490\n",
      "Epoch[5/15], Step [20/469], Reconst Loss: 10807.9707, KL Div: 3233.2664\n",
      "Epoch[5/15], Step [30/469], Reconst Loss: 10878.2461, KL Div: 3090.3259\n",
      "Epoch[5/15], Step [40/469], Reconst Loss: 10741.2100, KL Div: 3253.5762\n",
      "Epoch[5/15], Step [50/469], Reconst Loss: 10510.7559, KL Div: 3194.1968\n",
      "Epoch[5/15], Step [60/469], Reconst Loss: 10851.0078, KL Div: 3084.1436\n",
      "Epoch[5/15], Step [70/469], Reconst Loss: 10481.2793, KL Div: 3099.3994\n",
      "Epoch[5/15], Step [80/469], Reconst Loss: 10902.9668, KL Div: 3261.8918\n",
      "Epoch[5/15], Step [90/469], Reconst Loss: 10843.2236, KL Div: 3142.5327\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 10925.0205, KL Div: 3112.1841\n",
      "Epoch[5/15], Step [110/469], Reconst Loss: 11395.0098, KL Div: 3222.5239\n",
      "Epoch[5/15], Step [120/469], Reconst Loss: 11096.2041, KL Div: 3089.6316\n",
      "Epoch[5/15], Step [130/469], Reconst Loss: 10735.4629, KL Div: 3302.7156\n",
      "Epoch[5/15], Step [140/469], Reconst Loss: 11691.9619, KL Div: 3185.1060\n",
      "Epoch[5/15], Step [150/469], Reconst Loss: 11326.9014, KL Div: 3303.3586\n",
      "Epoch[5/15], Step [160/469], Reconst Loss: 10916.0840, KL Div: 3143.3164\n",
      "Epoch[5/15], Step [170/469], Reconst Loss: 11262.2861, KL Div: 3224.1494\n",
      "Epoch[5/15], Step [180/469], Reconst Loss: 11278.5000, KL Div: 3260.9546\n",
      "Epoch[5/15], Step [190/469], Reconst Loss: 11143.1875, KL Div: 3136.8628\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 10719.1963, KL Div: 3221.8904\n",
      "Epoch[5/15], Step [210/469], Reconst Loss: 10734.2559, KL Div: 3067.4419\n",
      "Epoch[5/15], Step [220/469], Reconst Loss: 11188.5342, KL Div: 3264.4717\n",
      "Epoch[5/15], Step [230/469], Reconst Loss: 11287.9150, KL Div: 3153.6045\n",
      "Epoch[5/15], Step [240/469], Reconst Loss: 11194.0957, KL Div: 3191.6589\n",
      "Epoch[5/15], Step [250/469], Reconst Loss: 11373.4102, KL Div: 3233.6426\n",
      "Epoch[5/15], Step [260/469], Reconst Loss: 10850.6445, KL Div: 3240.3735\n",
      "Epoch[5/15], Step [270/469], Reconst Loss: 11030.9219, KL Div: 3122.9429\n",
      "Epoch[5/15], Step [280/469], Reconst Loss: 10811.8838, KL Div: 3269.5642\n",
      "Epoch[5/15], Step [290/469], Reconst Loss: 10951.1113, KL Div: 3115.7974\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 10777.0859, KL Div: 3278.5288\n",
      "Epoch[5/15], Step [310/469], Reconst Loss: 11213.8936, KL Div: 3053.5859\n",
      "Epoch[5/15], Step [320/469], Reconst Loss: 10543.7256, KL Div: 3210.2256\n",
      "Epoch[5/15], Step [330/469], Reconst Loss: 10916.4463, KL Div: 3192.7446\n",
      "Epoch[5/15], Step [340/469], Reconst Loss: 10707.5879, KL Div: 3097.2859\n",
      "Epoch[5/15], Step [350/469], Reconst Loss: 10523.1777, KL Div: 3159.7356\n",
      "Epoch[5/15], Step [360/469], Reconst Loss: 10728.7129, KL Div: 3093.6201\n",
      "Epoch[5/15], Step [370/469], Reconst Loss: 10564.8164, KL Div: 3216.6426\n",
      "Epoch[5/15], Step [380/469], Reconst Loss: 11239.1055, KL Div: 3244.7556\n",
      "Epoch[5/15], Step [390/469], Reconst Loss: 10927.2031, KL Div: 3198.0896\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10728.8184, KL Div: 3114.7734\n",
      "Epoch[5/15], Step [410/469], Reconst Loss: 10405.1221, KL Div: 3103.6453\n",
      "Epoch[5/15], Step [420/469], Reconst Loss: 10169.5156, KL Div: 3076.3672\n",
      "Epoch[5/15], Step [430/469], Reconst Loss: 10350.8457, KL Div: 3134.3933\n",
      "Epoch[5/15], Step [440/469], Reconst Loss: 10679.9668, KL Div: 3140.6809\n",
      "Epoch[5/15], Step [450/469], Reconst Loss: 10708.3477, KL Div: 3141.5947\n",
      "Epoch[5/15], Step [460/469], Reconst Loss: 10713.2031, KL Div: 3023.2395\n",
      "Epoch[6/15], Step [10/469], Reconst Loss: 10976.9824, KL Div: 3087.0908\n",
      "Epoch[6/15], Step [20/469], Reconst Loss: 10910.7871, KL Div: 3172.1689\n",
      "Epoch[6/15], Step [30/469], Reconst Loss: 10746.6582, KL Div: 3292.1421\n",
      "Epoch[6/15], Step [40/469], Reconst Loss: 10873.9805, KL Div: 3273.5969\n",
      "Epoch[6/15], Step [50/469], Reconst Loss: 11575.6855, KL Div: 3157.9143\n",
      "Epoch[6/15], Step [60/469], Reconst Loss: 10352.6855, KL Div: 3172.6013\n",
      "Epoch[6/15], Step [70/469], Reconst Loss: 10892.8887, KL Div: 3180.4834\n",
      "Epoch[6/15], Step [80/469], Reconst Loss: 10524.7754, KL Div: 3146.2781\n",
      "Epoch[6/15], Step [90/469], Reconst Loss: 10948.1650, KL Div: 3233.2593\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 10530.4717, KL Div: 3164.7998\n",
      "Epoch[6/15], Step [110/469], Reconst Loss: 10485.0449, KL Div: 3290.9575\n",
      "Epoch[6/15], Step [120/469], Reconst Loss: 11192.6094, KL Div: 3186.2859\n",
      "Epoch[6/15], Step [130/469], Reconst Loss: 10521.5098, KL Div: 3290.8164\n",
      "Epoch[6/15], Step [140/469], Reconst Loss: 10528.7461, KL Div: 3173.6831\n",
      "Epoch[6/15], Step [150/469], Reconst Loss: 10525.8652, KL Div: 3165.8252\n",
      "Epoch[6/15], Step [160/469], Reconst Loss: 10838.1152, KL Div: 3241.4580\n",
      "Epoch[6/15], Step [170/469], Reconst Loss: 11438.8672, KL Div: 3195.1047\n",
      "Epoch[6/15], Step [180/469], Reconst Loss: 10073.8262, KL Div: 3128.6252\n",
      "Epoch[6/15], Step [190/469], Reconst Loss: 10852.0078, KL Div: 3287.1284\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 10644.7686, KL Div: 3242.9497\n",
      "Epoch[6/15], Step [210/469], Reconst Loss: 10396.8086, KL Div: 3145.4585\n",
      "Epoch[6/15], Step [220/469], Reconst Loss: 11078.4570, KL Div: 3258.2427\n",
      "Epoch[6/15], Step [230/469], Reconst Loss: 10623.7637, KL Div: 3153.9922\n",
      "Epoch[6/15], Step [240/469], Reconst Loss: 10591.2471, KL Div: 3177.3967\n",
      "Epoch[6/15], Step [250/469], Reconst Loss: 11038.3535, KL Div: 3149.9575\n",
      "Epoch[6/15], Step [260/469], Reconst Loss: 10698.2979, KL Div: 3268.0942\n",
      "Epoch[6/15], Step [270/469], Reconst Loss: 10426.5820, KL Div: 3188.6775\n",
      "Epoch[6/15], Step [280/469], Reconst Loss: 10514.0410, KL Div: 3177.2048\n",
      "Epoch[6/15], Step [290/469], Reconst Loss: 10493.8438, KL Div: 3215.9868\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10772.8291, KL Div: 3122.7163\n",
      "Epoch[6/15], Step [310/469], Reconst Loss: 10817.5547, KL Div: 3242.9536\n",
      "Epoch[6/15], Step [320/469], Reconst Loss: 10607.0625, KL Div: 3183.4758\n",
      "Epoch[6/15], Step [330/469], Reconst Loss: 10772.7354, KL Div: 3099.2378\n",
      "Epoch[6/15], Step [340/469], Reconst Loss: 10136.3418, KL Div: 3237.6855\n",
      "Epoch[6/15], Step [350/469], Reconst Loss: 10563.5820, KL Div: 3029.6299\n",
      "Epoch[6/15], Step [360/469], Reconst Loss: 10831.5078, KL Div: 3238.1707\n",
      "Epoch[6/15], Step [370/469], Reconst Loss: 10764.7656, KL Div: 3091.2515\n",
      "Epoch[6/15], Step [380/469], Reconst Loss: 10892.8496, KL Div: 3193.9236\n",
      "Epoch[6/15], Step [390/469], Reconst Loss: 10779.1836, KL Div: 3288.0581\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10674.2852, KL Div: 3249.2510\n",
      "Epoch[6/15], Step [410/469], Reconst Loss: 10493.4062, KL Div: 3176.2876\n",
      "Epoch[6/15], Step [420/469], Reconst Loss: 10585.6748, KL Div: 3222.4634\n",
      "Epoch[6/15], Step [430/469], Reconst Loss: 10869.2266, KL Div: 3232.8623\n",
      "Epoch[6/15], Step [440/469], Reconst Loss: 10887.1836, KL Div: 3151.3762\n",
      "Epoch[6/15], Step [450/469], Reconst Loss: 10604.6055, KL Div: 3280.5256\n",
      "Epoch[6/15], Step [460/469], Reconst Loss: 10388.7578, KL Div: 3159.8188\n",
      "Epoch[7/15], Step [10/469], Reconst Loss: 10406.4355, KL Div: 3184.0156\n",
      "Epoch[7/15], Step [20/469], Reconst Loss: 10701.7500, KL Div: 3115.4360\n",
      "Epoch[7/15], Step [30/469], Reconst Loss: 11040.5518, KL Div: 3225.8875\n",
      "Epoch[7/15], Step [40/469], Reconst Loss: 10731.6699, KL Div: 3251.3579\n",
      "Epoch[7/15], Step [50/469], Reconst Loss: 10369.3584, KL Div: 3182.9121\n",
      "Epoch[7/15], Step [60/469], Reconst Loss: 10909.2588, KL Div: 3194.0142\n",
      "Epoch[7/15], Step [70/469], Reconst Loss: 10730.6328, KL Div: 3176.9531\n",
      "Epoch[7/15], Step [80/469], Reconst Loss: 10797.3447, KL Div: 3229.5505\n",
      "Epoch[7/15], Step [90/469], Reconst Loss: 10912.1504, KL Div: 3132.6467\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 10169.9561, KL Div: 3225.5903\n",
      "Epoch[7/15], Step [110/469], Reconst Loss: 11235.4941, KL Div: 3216.9277\n",
      "Epoch[7/15], Step [120/469], Reconst Loss: 10771.4385, KL Div: 3313.1433\n",
      "Epoch[7/15], Step [130/469], Reconst Loss: 10938.2344, KL Div: 3108.3760\n",
      "Epoch[7/15], Step [140/469], Reconst Loss: 10501.6963, KL Div: 3163.2161\n",
      "Epoch[7/15], Step [150/469], Reconst Loss: 10581.7852, KL Div: 3287.1118\n",
      "Epoch[7/15], Step [160/469], Reconst Loss: 10518.4277, KL Div: 3129.7844\n",
      "Epoch[7/15], Step [170/469], Reconst Loss: 10136.9434, KL Div: 3240.9321\n",
      "Epoch[7/15], Step [180/469], Reconst Loss: 10541.8164, KL Div: 3204.4341\n",
      "Epoch[7/15], Step [190/469], Reconst Loss: 10441.5420, KL Div: 3127.6167\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 9916.2168, KL Div: 3125.0083\n",
      "Epoch[7/15], Step [210/469], Reconst Loss: 10422.0693, KL Div: 3112.2644\n",
      "Epoch[7/15], Step [220/469], Reconst Loss: 10475.1260, KL Div: 3225.3264\n",
      "Epoch[7/15], Step [230/469], Reconst Loss: 10346.6875, KL Div: 3162.3691\n",
      "Epoch[7/15], Step [240/469], Reconst Loss: 10510.1621, KL Div: 3102.8445\n",
      "Epoch[7/15], Step [250/469], Reconst Loss: 10723.7812, KL Div: 3318.2910\n",
      "Epoch[7/15], Step [260/469], Reconst Loss: 10651.9375, KL Div: 3163.7893\n",
      "Epoch[7/15], Step [270/469], Reconst Loss: 10369.8877, KL Div: 3218.6003\n",
      "Epoch[7/15], Step [280/469], Reconst Loss: 10458.5156, KL Div: 3207.7747\n",
      "Epoch[7/15], Step [290/469], Reconst Loss: 10716.4150, KL Div: 3190.0461\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10536.0928, KL Div: 3061.4431\n",
      "Epoch[7/15], Step [310/469], Reconst Loss: 10375.4668, KL Div: 3208.8054\n",
      "Epoch[7/15], Step [320/469], Reconst Loss: 11022.7285, KL Div: 3172.2195\n",
      "Epoch[7/15], Step [330/469], Reconst Loss: 10395.7529, KL Div: 3213.1978\n",
      "Epoch[7/15], Step [340/469], Reconst Loss: 10408.5820, KL Div: 3189.8367\n",
      "Epoch[7/15], Step [350/469], Reconst Loss: 10594.5410, KL Div: 3207.4275\n",
      "Epoch[7/15], Step [360/469], Reconst Loss: 10608.4219, KL Div: 3186.2986\n",
      "Epoch[7/15], Step [370/469], Reconst Loss: 10277.3740, KL Div: 3175.2854\n",
      "Epoch[7/15], Step [380/469], Reconst Loss: 10618.7949, KL Div: 3170.9600\n",
      "Epoch[7/15], Step [390/469], Reconst Loss: 10543.3057, KL Div: 3146.8489\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10817.5664, KL Div: 3260.7778\n",
      "Epoch[7/15], Step [410/469], Reconst Loss: 10907.2227, KL Div: 3275.5435\n",
      "Epoch[7/15], Step [420/469], Reconst Loss: 10475.4238, KL Div: 3133.6787\n",
      "Epoch[7/15], Step [430/469], Reconst Loss: 10898.4619, KL Div: 3193.8254\n",
      "Epoch[7/15], Step [440/469], Reconst Loss: 10181.1797, KL Div: 3197.0381\n",
      "Epoch[7/15], Step [450/469], Reconst Loss: 10857.4531, KL Div: 3302.2529\n",
      "Epoch[7/15], Step [460/469], Reconst Loss: 10671.1055, KL Div: 3202.8901\n",
      "Epoch[8/15], Step [10/469], Reconst Loss: 10624.8125, KL Div: 3230.2720\n",
      "Epoch[8/15], Step [20/469], Reconst Loss: 10549.9082, KL Div: 3237.6155\n",
      "Epoch[8/15], Step [30/469], Reconst Loss: 10491.4111, KL Div: 3129.3835\n",
      "Epoch[8/15], Step [40/469], Reconst Loss: 10466.7676, KL Div: 3220.6357\n",
      "Epoch[8/15], Step [50/469], Reconst Loss: 10424.5020, KL Div: 3193.2893\n",
      "Epoch[8/15], Step [60/469], Reconst Loss: 10717.3203, KL Div: 3230.4805\n",
      "Epoch[8/15], Step [70/469], Reconst Loss: 10418.1660, KL Div: 3242.8176\n",
      "Epoch[8/15], Step [80/469], Reconst Loss: 10260.3535, KL Div: 3106.4731\n",
      "Epoch[8/15], Step [90/469], Reconst Loss: 10757.8789, KL Div: 3180.3354\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 10440.7764, KL Div: 3339.0613\n",
      "Epoch[8/15], Step [110/469], Reconst Loss: 10658.0742, KL Div: 3240.5566\n",
      "Epoch[8/15], Step [120/469], Reconst Loss: 10495.1523, KL Div: 3099.8196\n",
      "Epoch[8/15], Step [130/469], Reconst Loss: 10864.4873, KL Div: 3294.7590\n",
      "Epoch[8/15], Step [140/469], Reconst Loss: 10359.9902, KL Div: 3128.6343\n",
      "Epoch[8/15], Step [150/469], Reconst Loss: 10972.9570, KL Div: 3260.5696\n",
      "Epoch[8/15], Step [160/469], Reconst Loss: 10198.7803, KL Div: 3182.4866\n",
      "Epoch[8/15], Step [170/469], Reconst Loss: 10666.8809, KL Div: 3273.2881\n",
      "Epoch[8/15], Step [180/469], Reconst Loss: 10969.9512, KL Div: 3362.6582\n",
      "Epoch[8/15], Step [190/469], Reconst Loss: 10825.3262, KL Div: 3273.0176\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 9994.4004, KL Div: 3196.8147\n",
      "Epoch[8/15], Step [210/469], Reconst Loss: 10539.9697, KL Div: 3283.8083\n",
      "Epoch[8/15], Step [220/469], Reconst Loss: 10345.8535, KL Div: 3229.7031\n",
      "Epoch[8/15], Step [230/469], Reconst Loss: 10868.6348, KL Div: 3263.5730\n",
      "Epoch[8/15], Step [240/469], Reconst Loss: 10614.6621, KL Div: 3243.2656\n",
      "Epoch[8/15], Step [250/469], Reconst Loss: 10522.7793, KL Div: 3231.8030\n",
      "Epoch[8/15], Step [260/469], Reconst Loss: 10218.8770, KL Div: 3170.9343\n",
      "Epoch[8/15], Step [270/469], Reconst Loss: 10555.2803, KL Div: 3165.3516\n",
      "Epoch[8/15], Step [280/469], Reconst Loss: 10656.7852, KL Div: 3264.8340\n",
      "Epoch[8/15], Step [290/469], Reconst Loss: 10536.2422, KL Div: 3205.2195\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10326.5449, KL Div: 3126.3608\n",
      "Epoch[8/15], Step [310/469], Reconst Loss: 10729.1152, KL Div: 3229.2690\n",
      "Epoch[8/15], Step [320/469], Reconst Loss: 10494.9199, KL Div: 3266.9915\n",
      "Epoch[8/15], Step [330/469], Reconst Loss: 10461.9062, KL Div: 3237.3086\n",
      "Epoch[8/15], Step [340/469], Reconst Loss: 10591.4199, KL Div: 3125.5557\n",
      "Epoch[8/15], Step [350/469], Reconst Loss: 10299.4326, KL Div: 3229.1592\n",
      "Epoch[8/15], Step [360/469], Reconst Loss: 10572.4297, KL Div: 3215.1611\n",
      "Epoch[8/15], Step [370/469], Reconst Loss: 10719.3838, KL Div: 3259.7124\n",
      "Epoch[8/15], Step [380/469], Reconst Loss: 10830.3750, KL Div: 3243.4033\n",
      "Epoch[8/15], Step [390/469], Reconst Loss: 10950.9121, KL Div: 3183.1509\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 11131.7568, KL Div: 3147.8535\n",
      "Epoch[8/15], Step [410/469], Reconst Loss: 10622.3389, KL Div: 3242.4453\n",
      "Epoch[8/15], Step [420/469], Reconst Loss: 10289.9004, KL Div: 3162.5405\n",
      "Epoch[8/15], Step [430/469], Reconst Loss: 10446.3789, KL Div: 3216.9229\n",
      "Epoch[8/15], Step [440/469], Reconst Loss: 10578.2725, KL Div: 3228.1631\n",
      "Epoch[8/15], Step [450/469], Reconst Loss: 10572.7451, KL Div: 3171.6204\n",
      "Epoch[8/15], Step [460/469], Reconst Loss: 10518.0078, KL Div: 3270.4153\n",
      "Epoch[9/15], Step [10/469], Reconst Loss: 10117.2109, KL Div: 3196.0754\n",
      "Epoch[9/15], Step [20/469], Reconst Loss: 10479.4814, KL Div: 3235.7207\n",
      "Epoch[9/15], Step [30/469], Reconst Loss: 10462.3789, KL Div: 3162.7893\n",
      "Epoch[9/15], Step [40/469], Reconst Loss: 11142.2744, KL Div: 3190.2812\n",
      "Epoch[9/15], Step [50/469], Reconst Loss: 10489.4004, KL Div: 3247.3335\n",
      "Epoch[9/15], Step [60/469], Reconst Loss: 10547.9688, KL Div: 3233.5823\n",
      "Epoch[9/15], Step [70/469], Reconst Loss: 10431.6494, KL Div: 3234.7471\n",
      "Epoch[9/15], Step [80/469], Reconst Loss: 10608.3145, KL Div: 3310.3027\n",
      "Epoch[9/15], Step [90/469], Reconst Loss: 10549.6318, KL Div: 3254.6833\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 11067.6113, KL Div: 3347.3562\n",
      "Epoch[9/15], Step [110/469], Reconst Loss: 10353.6807, KL Div: 3100.5693\n",
      "Epoch[9/15], Step [120/469], Reconst Loss: 10611.4062, KL Div: 3296.5220\n",
      "Epoch[9/15], Step [130/469], Reconst Loss: 10633.5215, KL Div: 3219.3508\n",
      "Epoch[9/15], Step [140/469], Reconst Loss: 10531.7949, KL Div: 3307.5115\n",
      "Epoch[9/15], Step [150/469], Reconst Loss: 11064.7100, KL Div: 3191.5845\n",
      "Epoch[9/15], Step [160/469], Reconst Loss: 10571.0088, KL Div: 3293.3694\n",
      "Epoch[9/15], Step [170/469], Reconst Loss: 10562.8369, KL Div: 3189.2808\n",
      "Epoch[9/15], Step [180/469], Reconst Loss: 10308.2285, KL Div: 3194.6545\n",
      "Epoch[9/15], Step [190/469], Reconst Loss: 10613.6758, KL Div: 3307.9556\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 10833.0605, KL Div: 3320.8274\n",
      "Epoch[9/15], Step [210/469], Reconst Loss: 10617.0381, KL Div: 3196.3091\n",
      "Epoch[9/15], Step [220/469], Reconst Loss: 10245.7266, KL Div: 3231.9092\n",
      "Epoch[9/15], Step [230/469], Reconst Loss: 10240.6289, KL Div: 3041.9170\n",
      "Epoch[9/15], Step [240/469], Reconst Loss: 10865.1250, KL Div: 3322.3037\n",
      "Epoch[9/15], Step [250/469], Reconst Loss: 10035.8887, KL Div: 3119.8335\n",
      "Epoch[9/15], Step [260/469], Reconst Loss: 10252.5342, KL Div: 3234.7312\n",
      "Epoch[9/15], Step [270/469], Reconst Loss: 10580.9297, KL Div: 3264.7930\n",
      "Epoch[9/15], Step [280/469], Reconst Loss: 10683.9180, KL Div: 3176.7917\n",
      "Epoch[9/15], Step [290/469], Reconst Loss: 10863.5166, KL Div: 3223.8340\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10090.2188, KL Div: 3265.0183\n",
      "Epoch[9/15], Step [310/469], Reconst Loss: 10772.8760, KL Div: 3159.3257\n",
      "Epoch[9/15], Step [320/469], Reconst Loss: 10368.2080, KL Div: 3230.6816\n",
      "Epoch[9/15], Step [330/469], Reconst Loss: 10597.6133, KL Div: 3300.4382\n",
      "Epoch[9/15], Step [340/469], Reconst Loss: 10364.3379, KL Div: 3202.3438\n",
      "Epoch[9/15], Step [350/469], Reconst Loss: 10818.0312, KL Div: 3239.9907\n",
      "Epoch[9/15], Step [360/469], Reconst Loss: 10446.6562, KL Div: 3298.5745\n",
      "Epoch[9/15], Step [370/469], Reconst Loss: 10173.2715, KL Div: 3171.0308\n",
      "Epoch[9/15], Step [380/469], Reconst Loss: 10501.0947, KL Div: 3317.9470\n",
      "Epoch[9/15], Step [390/469], Reconst Loss: 10721.6289, KL Div: 3268.9155\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 10565.0195, KL Div: 3253.0513\n",
      "Epoch[9/15], Step [410/469], Reconst Loss: 10400.9805, KL Div: 3176.0586\n",
      "Epoch[9/15], Step [420/469], Reconst Loss: 10237.5508, KL Div: 3180.9939\n",
      "Epoch[9/15], Step [430/469], Reconst Loss: 10115.4844, KL Div: 3183.1121\n",
      "Epoch[9/15], Step [440/469], Reconst Loss: 10614.5205, KL Div: 3181.1079\n",
      "Epoch[9/15], Step [450/469], Reconst Loss: 10463.7832, KL Div: 3274.3108\n",
      "Epoch[9/15], Step [460/469], Reconst Loss: 10596.3945, KL Div: 3252.9473\n",
      "Epoch[10/15], Step [10/469], Reconst Loss: 10763.3945, KL Div: 3248.1450\n",
      "Epoch[10/15], Step [20/469], Reconst Loss: 10745.4082, KL Div: 3307.7373\n",
      "Epoch[10/15], Step [30/469], Reconst Loss: 10138.1748, KL Div: 3207.3188\n",
      "Epoch[10/15], Step [40/469], Reconst Loss: 10612.9502, KL Div: 3244.4182\n",
      "Epoch[10/15], Step [50/469], Reconst Loss: 10113.0996, KL Div: 3275.7483\n",
      "Epoch[10/15], Step [60/469], Reconst Loss: 10491.6582, KL Div: 3354.4463\n",
      "Epoch[10/15], Step [70/469], Reconst Loss: 10441.8613, KL Div: 3169.1479\n",
      "Epoch[10/15], Step [80/469], Reconst Loss: 10124.7031, KL Div: 3282.9062\n",
      "Epoch[10/15], Step [90/469], Reconst Loss: 10185.5938, KL Div: 3140.9270\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 10467.5645, KL Div: 3258.8015\n",
      "Epoch[10/15], Step [110/469], Reconst Loss: 10728.0723, KL Div: 3189.1062\n",
      "Epoch[10/15], Step [120/469], Reconst Loss: 10465.2861, KL Div: 3152.4827\n",
      "Epoch[10/15], Step [130/469], Reconst Loss: 10648.6318, KL Div: 3378.8044\n",
      "Epoch[10/15], Step [140/469], Reconst Loss: 10397.2373, KL Div: 3165.4746\n",
      "Epoch[10/15], Step [150/469], Reconst Loss: 10208.0879, KL Div: 3231.0066\n",
      "Epoch[10/15], Step [160/469], Reconst Loss: 10391.7559, KL Div: 3204.8025\n",
      "Epoch[10/15], Step [170/469], Reconst Loss: 10022.6660, KL Div: 3135.6660\n",
      "Epoch[10/15], Step [180/469], Reconst Loss: 10518.8477, KL Div: 3103.7754\n",
      "Epoch[10/15], Step [190/469], Reconst Loss: 10373.9580, KL Div: 3138.2336\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10433.6084, KL Div: 3300.1782\n",
      "Epoch[10/15], Step [210/469], Reconst Loss: 10536.8252, KL Div: 3316.9746\n",
      "Epoch[10/15], Step [220/469], Reconst Loss: 10459.5898, KL Div: 3225.2043\n",
      "Epoch[10/15], Step [230/469], Reconst Loss: 10717.2812, KL Div: 3184.2280\n",
      "Epoch[10/15], Step [240/469], Reconst Loss: 10225.3848, KL Div: 3254.3091\n",
      "Epoch[10/15], Step [250/469], Reconst Loss: 10406.2061, KL Div: 3209.5493\n",
      "Epoch[10/15], Step [260/469], Reconst Loss: 10208.3867, KL Div: 3216.1069\n",
      "Epoch[10/15], Step [270/469], Reconst Loss: 11073.3809, KL Div: 3232.2266\n",
      "Epoch[10/15], Step [280/469], Reconst Loss: 10446.2080, KL Div: 3242.0974\n",
      "Epoch[10/15], Step [290/469], Reconst Loss: 10221.5117, KL Div: 3185.5574\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10979.0859, KL Div: 3426.2246\n",
      "Epoch[10/15], Step [310/469], Reconst Loss: 10787.1670, KL Div: 3271.8452\n",
      "Epoch[10/15], Step [320/469], Reconst Loss: 10455.5078, KL Div: 3252.5681\n",
      "Epoch[10/15], Step [330/469], Reconst Loss: 10702.6855, KL Div: 3343.9097\n",
      "Epoch[10/15], Step [340/469], Reconst Loss: 10661.5498, KL Div: 3389.3469\n",
      "Epoch[10/15], Step [350/469], Reconst Loss: 10682.1504, KL Div: 3284.8674\n",
      "Epoch[10/15], Step [360/469], Reconst Loss: 10414.1016, KL Div: 3225.1824\n",
      "Epoch[10/15], Step [370/469], Reconst Loss: 10555.2402, KL Div: 3128.1589\n",
      "Epoch[10/15], Step [380/469], Reconst Loss: 10111.9287, KL Div: 3151.3833\n",
      "Epoch[10/15], Step [390/469], Reconst Loss: 9813.5723, KL Div: 3139.5474\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 10036.3164, KL Div: 3166.3872\n",
      "Epoch[10/15], Step [410/469], Reconst Loss: 10145.3184, KL Div: 3212.8887\n",
      "Epoch[10/15], Step [420/469], Reconst Loss: 10919.9756, KL Div: 3175.6724\n",
      "Epoch[10/15], Step [430/469], Reconst Loss: 10310.0654, KL Div: 3226.6416\n",
      "Epoch[10/15], Step [440/469], Reconst Loss: 9775.1855, KL Div: 3166.0112\n",
      "Epoch[10/15], Step [450/469], Reconst Loss: 10372.0166, KL Div: 3190.3079\n",
      "Epoch[10/15], Step [460/469], Reconst Loss: 10274.0166, KL Div: 3126.3867\n",
      "Epoch[11/15], Step [10/469], Reconst Loss: 10236.4961, KL Div: 3332.2322\n",
      "Epoch[11/15], Step [20/469], Reconst Loss: 10820.1621, KL Div: 3229.4238\n",
      "Epoch[11/15], Step [30/469], Reconst Loss: 10322.8408, KL Div: 3201.8647\n",
      "Epoch[11/15], Step [40/469], Reconst Loss: 10663.7461, KL Div: 3197.9927\n",
      "Epoch[11/15], Step [50/469], Reconst Loss: 10654.8574, KL Div: 3308.6086\n",
      "Epoch[11/15], Step [60/469], Reconst Loss: 9894.3574, KL Div: 3187.5193\n",
      "Epoch[11/15], Step [70/469], Reconst Loss: 10483.8613, KL Div: 3326.8582\n",
      "Epoch[11/15], Step [80/469], Reconst Loss: 10687.2461, KL Div: 3355.7717\n",
      "Epoch[11/15], Step [90/469], Reconst Loss: 10304.8477, KL Div: 3207.7637\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 10051.3203, KL Div: 3276.8579\n",
      "Epoch[11/15], Step [110/469], Reconst Loss: 9980.4443, KL Div: 3169.9424\n",
      "Epoch[11/15], Step [120/469], Reconst Loss: 10317.3535, KL Div: 3216.7961\n",
      "Epoch[11/15], Step [130/469], Reconst Loss: 10607.3027, KL Div: 3211.9512\n",
      "Epoch[11/15], Step [140/469], Reconst Loss: 10482.5430, KL Div: 3158.9011\n",
      "Epoch[11/15], Step [150/469], Reconst Loss: 10364.8984, KL Div: 3280.1353\n",
      "Epoch[11/15], Step [160/469], Reconst Loss: 10396.0000, KL Div: 3258.4263\n",
      "Epoch[11/15], Step [170/469], Reconst Loss: 10394.4902, KL Div: 3191.8691\n",
      "Epoch[11/15], Step [180/469], Reconst Loss: 10531.1035, KL Div: 3227.4998\n",
      "Epoch[11/15], Step [190/469], Reconst Loss: 9842.3086, KL Div: 3169.5925\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 10451.8916, KL Div: 3195.4902\n",
      "Epoch[11/15], Step [210/469], Reconst Loss: 10600.6270, KL Div: 3199.6404\n",
      "Epoch[11/15], Step [220/469], Reconst Loss: 10382.9150, KL Div: 3314.6846\n",
      "Epoch[11/15], Step [230/469], Reconst Loss: 10759.0332, KL Div: 3308.4021\n",
      "Epoch[11/15], Step [240/469], Reconst Loss: 10041.6621, KL Div: 3226.4097\n",
      "Epoch[11/15], Step [250/469], Reconst Loss: 10354.3818, KL Div: 3293.3445\n",
      "Epoch[11/15], Step [260/469], Reconst Loss: 10491.7363, KL Div: 3148.7295\n",
      "Epoch[11/15], Step [270/469], Reconst Loss: 10456.7686, KL Div: 3329.5156\n",
      "Epoch[11/15], Step [280/469], Reconst Loss: 10343.6152, KL Div: 3206.4287\n",
      "Epoch[11/15], Step [290/469], Reconst Loss: 10688.1230, KL Div: 3320.9771\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 10483.0215, KL Div: 3183.2302\n",
      "Epoch[11/15], Step [310/469], Reconst Loss: 10304.2236, KL Div: 3162.1362\n",
      "Epoch[11/15], Step [320/469], Reconst Loss: 10498.0850, KL Div: 3251.5730\n",
      "Epoch[11/15], Step [330/469], Reconst Loss: 10792.5742, KL Div: 3221.1631\n",
      "Epoch[11/15], Step [340/469], Reconst Loss: 10022.6650, KL Div: 3194.6606\n",
      "Epoch[11/15], Step [350/469], Reconst Loss: 10127.6992, KL Div: 3274.7615\n",
      "Epoch[11/15], Step [360/469], Reconst Loss: 10427.9258, KL Div: 3112.2668\n",
      "Epoch[11/15], Step [370/469], Reconst Loss: 10455.5283, KL Div: 3244.4829\n",
      "Epoch[11/15], Step [380/469], Reconst Loss: 10300.6650, KL Div: 3150.2559\n",
      "Epoch[11/15], Step [390/469], Reconst Loss: 10782.0977, KL Div: 3268.0913\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 10992.9678, KL Div: 3347.2024\n",
      "Epoch[11/15], Step [410/469], Reconst Loss: 10246.1543, KL Div: 3174.8882\n",
      "Epoch[11/15], Step [420/469], Reconst Loss: 10202.9082, KL Div: 3187.4268\n",
      "Epoch[11/15], Step [430/469], Reconst Loss: 10129.3760, KL Div: 3241.7512\n",
      "Epoch[11/15], Step [440/469], Reconst Loss: 10590.9766, KL Div: 3342.1084\n",
      "Epoch[11/15], Step [450/469], Reconst Loss: 10516.0088, KL Div: 3222.8481\n",
      "Epoch[11/15], Step [460/469], Reconst Loss: 10112.9326, KL Div: 3144.4690\n",
      "Epoch[12/15], Step [10/469], Reconst Loss: 10352.6543, KL Div: 3264.0723\n",
      "Epoch[12/15], Step [20/469], Reconst Loss: 10636.6934, KL Div: 3326.1582\n",
      "Epoch[12/15], Step [30/469], Reconst Loss: 10441.6387, KL Div: 3197.1443\n",
      "Epoch[12/15], Step [40/469], Reconst Loss: 10377.6934, KL Div: 3258.8008\n",
      "Epoch[12/15], Step [50/469], Reconst Loss: 9976.5938, KL Div: 3143.9358\n",
      "Epoch[12/15], Step [60/469], Reconst Loss: 10048.3936, KL Div: 3262.0640\n",
      "Epoch[12/15], Step [70/469], Reconst Loss: 9958.0352, KL Div: 3136.9700\n",
      "Epoch[12/15], Step [80/469], Reconst Loss: 10798.0596, KL Div: 3264.6008\n",
      "Epoch[12/15], Step [90/469], Reconst Loss: 10082.4238, KL Div: 3308.3909\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 10225.7285, KL Div: 3184.2229\n",
      "Epoch[12/15], Step [110/469], Reconst Loss: 10526.1270, KL Div: 3225.7539\n",
      "Epoch[12/15], Step [120/469], Reconst Loss: 10202.1260, KL Div: 3307.1375\n",
      "Epoch[12/15], Step [130/469], Reconst Loss: 11002.5312, KL Div: 3195.8447\n",
      "Epoch[12/15], Step [140/469], Reconst Loss: 10566.2998, KL Div: 3232.7212\n",
      "Epoch[12/15], Step [150/469], Reconst Loss: 10345.6689, KL Div: 3239.5588\n",
      "Epoch[12/15], Step [160/469], Reconst Loss: 10191.8340, KL Div: 3161.4263\n",
      "Epoch[12/15], Step [170/469], Reconst Loss: 10710.5654, KL Div: 3162.0518\n",
      "Epoch[12/15], Step [180/469], Reconst Loss: 10275.7129, KL Div: 3314.6270\n",
      "Epoch[12/15], Step [190/469], Reconst Loss: 10269.2783, KL Div: 3167.0928\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 10392.6270, KL Div: 3196.5574\n",
      "Epoch[12/15], Step [210/469], Reconst Loss: 10345.4629, KL Div: 3192.6938\n",
      "Epoch[12/15], Step [220/469], Reconst Loss: 9910.5850, KL Div: 3208.3650\n",
      "Epoch[12/15], Step [230/469], Reconst Loss: 10404.1250, KL Div: 3291.0532\n",
      "Epoch[12/15], Step [240/469], Reconst Loss: 10240.7021, KL Div: 3233.7168\n",
      "Epoch[12/15], Step [250/469], Reconst Loss: 10167.4961, KL Div: 3191.7092\n",
      "Epoch[12/15], Step [260/469], Reconst Loss: 10327.4648, KL Div: 3269.0017\n",
      "Epoch[12/15], Step [270/469], Reconst Loss: 10538.9082, KL Div: 3280.0989\n",
      "Epoch[12/15], Step [280/469], Reconst Loss: 10158.5781, KL Div: 3191.5776\n",
      "Epoch[12/15], Step [290/469], Reconst Loss: 10112.6504, KL Div: 3167.4353\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 10381.7871, KL Div: 3227.5854\n",
      "Epoch[12/15], Step [310/469], Reconst Loss: 9559.1230, KL Div: 3135.3174\n",
      "Epoch[12/15], Step [320/469], Reconst Loss: 10715.1074, KL Div: 3257.7749\n",
      "Epoch[12/15], Step [330/469], Reconst Loss: 10210.0996, KL Div: 3316.1565\n",
      "Epoch[12/15], Step [340/469], Reconst Loss: 10819.2393, KL Div: 3287.6907\n",
      "Epoch[12/15], Step [350/469], Reconst Loss: 10219.7646, KL Div: 3195.8096\n",
      "Epoch[12/15], Step [360/469], Reconst Loss: 10052.7793, KL Div: 3180.8169\n",
      "Epoch[12/15], Step [370/469], Reconst Loss: 10297.8701, KL Div: 3288.8630\n",
      "Epoch[12/15], Step [380/469], Reconst Loss: 10275.9473, KL Div: 3173.2256\n",
      "Epoch[12/15], Step [390/469], Reconst Loss: 9851.4219, KL Div: 3222.5483\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10333.4453, KL Div: 3209.4028\n",
      "Epoch[12/15], Step [410/469], Reconst Loss: 10159.3691, KL Div: 3154.2043\n",
      "Epoch[12/15], Step [420/469], Reconst Loss: 10329.9697, KL Div: 3203.3555\n",
      "Epoch[12/15], Step [430/469], Reconst Loss: 10394.5225, KL Div: 3197.0808\n",
      "Epoch[12/15], Step [440/469], Reconst Loss: 10185.7461, KL Div: 3181.3723\n",
      "Epoch[12/15], Step [450/469], Reconst Loss: 10711.6543, KL Div: 3284.5317\n",
      "Epoch[12/15], Step [460/469], Reconst Loss: 10733.8672, KL Div: 3212.2627\n",
      "Epoch[13/15], Step [10/469], Reconst Loss: 10135.6504, KL Div: 3311.8496\n",
      "Epoch[13/15], Step [20/469], Reconst Loss: 9887.4102, KL Div: 3155.7358\n",
      "Epoch[13/15], Step [30/469], Reconst Loss: 10373.0156, KL Div: 3258.1338\n",
      "Epoch[13/15], Step [40/469], Reconst Loss: 10401.7930, KL Div: 3306.1077\n",
      "Epoch[13/15], Step [50/469], Reconst Loss: 9920.0605, KL Div: 3143.4307\n",
      "Epoch[13/15], Step [60/469], Reconst Loss: 10225.4297, KL Div: 3225.4233\n",
      "Epoch[13/15], Step [70/469], Reconst Loss: 10465.4541, KL Div: 3368.7515\n",
      "Epoch[13/15], Step [80/469], Reconst Loss: 10181.8584, KL Div: 3231.9949\n",
      "Epoch[13/15], Step [90/469], Reconst Loss: 10008.9229, KL Div: 3209.7678\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 10228.5205, KL Div: 3295.7480\n",
      "Epoch[13/15], Step [110/469], Reconst Loss: 10562.0762, KL Div: 3211.9111\n",
      "Epoch[13/15], Step [120/469], Reconst Loss: 10251.4258, KL Div: 3245.8787\n",
      "Epoch[13/15], Step [130/469], Reconst Loss: 10550.2588, KL Div: 3299.5820\n",
      "Epoch[13/15], Step [140/469], Reconst Loss: 9779.8105, KL Div: 3194.4692\n",
      "Epoch[13/15], Step [150/469], Reconst Loss: 10339.8965, KL Div: 3251.3374\n",
      "Epoch[13/15], Step [160/469], Reconst Loss: 9950.8164, KL Div: 3229.4756\n",
      "Epoch[13/15], Step [170/469], Reconst Loss: 9993.9160, KL Div: 3120.3057\n",
      "Epoch[13/15], Step [180/469], Reconst Loss: 10262.9570, KL Div: 3239.6443\n",
      "Epoch[13/15], Step [190/469], Reconst Loss: 9956.4033, KL Div: 3261.6165\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 10182.2529, KL Div: 3099.7217\n",
      "Epoch[13/15], Step [210/469], Reconst Loss: 10323.0244, KL Div: 3271.2249\n",
      "Epoch[13/15], Step [220/469], Reconst Loss: 10165.4541, KL Div: 3187.5637\n",
      "Epoch[13/15], Step [230/469], Reconst Loss: 10535.7393, KL Div: 3204.5103\n",
      "Epoch[13/15], Step [240/469], Reconst Loss: 10174.3975, KL Div: 3226.2444\n",
      "Epoch[13/15], Step [250/469], Reconst Loss: 10391.8496, KL Div: 3229.7622\n",
      "Epoch[13/15], Step [260/469], Reconst Loss: 10296.6113, KL Div: 3323.0066\n",
      "Epoch[13/15], Step [270/469], Reconst Loss: 10017.2666, KL Div: 3266.7290\n",
      "Epoch[13/15], Step [280/469], Reconst Loss: 9985.6455, KL Div: 3144.2422\n",
      "Epoch[13/15], Step [290/469], Reconst Loss: 10095.1113, KL Div: 3310.9644\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 10287.4570, KL Div: 3167.2207\n",
      "Epoch[13/15], Step [310/469], Reconst Loss: 10188.4209, KL Div: 3289.4802\n",
      "Epoch[13/15], Step [320/469], Reconst Loss: 10644.9316, KL Div: 3301.0308\n",
      "Epoch[13/15], Step [330/469], Reconst Loss: 10607.0918, KL Div: 3281.8987\n",
      "Epoch[13/15], Step [340/469], Reconst Loss: 10559.6523, KL Div: 3286.0520\n",
      "Epoch[13/15], Step [350/469], Reconst Loss: 10211.0225, KL Div: 3142.6411\n",
      "Epoch[13/15], Step [360/469], Reconst Loss: 10028.1250, KL Div: 3184.2715\n",
      "Epoch[13/15], Step [370/469], Reconst Loss: 10585.5332, KL Div: 3265.5610\n",
      "Epoch[13/15], Step [380/469], Reconst Loss: 10458.2480, KL Div: 3309.9785\n",
      "Epoch[13/15], Step [390/469], Reconst Loss: 10028.3721, KL Div: 3113.6079\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 9816.0762, KL Div: 3258.6611\n",
      "Epoch[13/15], Step [410/469], Reconst Loss: 10013.8242, KL Div: 3176.9309\n",
      "Epoch[13/15], Step [420/469], Reconst Loss: 10527.2246, KL Div: 3229.3706\n",
      "Epoch[13/15], Step [430/469], Reconst Loss: 10028.4004, KL Div: 3107.5396\n",
      "Epoch[13/15], Step [440/469], Reconst Loss: 10380.4531, KL Div: 3326.2651\n",
      "Epoch[13/15], Step [450/469], Reconst Loss: 10146.3223, KL Div: 3272.0918\n",
      "Epoch[13/15], Step [460/469], Reconst Loss: 10729.2441, KL Div: 3241.2803\n",
      "Epoch[14/15], Step [10/469], Reconst Loss: 10086.9912, KL Div: 3203.6387\n",
      "Epoch[14/15], Step [20/469], Reconst Loss: 10421.1328, KL Div: 3279.9370\n",
      "Epoch[14/15], Step [30/469], Reconst Loss: 10515.2529, KL Div: 3313.8589\n",
      "Epoch[14/15], Step [40/469], Reconst Loss: 10255.2725, KL Div: 3195.2866\n",
      "Epoch[14/15], Step [50/469], Reconst Loss: 10154.8535, KL Div: 3343.7456\n",
      "Epoch[14/15], Step [60/469], Reconst Loss: 10190.6299, KL Div: 3248.7698\n",
      "Epoch[14/15], Step [70/469], Reconst Loss: 10048.4727, KL Div: 3249.8479\n",
      "Epoch[14/15], Step [80/469], Reconst Loss: 10530.5479, KL Div: 3256.3491\n",
      "Epoch[14/15], Step [90/469], Reconst Loss: 9610.7598, KL Div: 3111.7759\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 10059.5430, KL Div: 3149.9941\n",
      "Epoch[14/15], Step [110/469], Reconst Loss: 10703.8994, KL Div: 3315.7466\n",
      "Epoch[14/15], Step [120/469], Reconst Loss: 10162.8545, KL Div: 3393.0127\n",
      "Epoch[14/15], Step [130/469], Reconst Loss: 10468.5801, KL Div: 3088.2749\n",
      "Epoch[14/15], Step [140/469], Reconst Loss: 10669.1074, KL Div: 3257.0813\n",
      "Epoch[14/15], Step [150/469], Reconst Loss: 10580.3828, KL Div: 3238.8652\n",
      "Epoch[14/15], Step [160/469], Reconst Loss: 10273.4229, KL Div: 3384.0024\n",
      "Epoch[14/15], Step [170/469], Reconst Loss: 10221.4551, KL Div: 3233.6882\n",
      "Epoch[14/15], Step [180/469], Reconst Loss: 10425.5488, KL Div: 3286.1313\n",
      "Epoch[14/15], Step [190/469], Reconst Loss: 10093.3340, KL Div: 3304.4165\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 10063.8965, KL Div: 3228.3376\n",
      "Epoch[14/15], Step [210/469], Reconst Loss: 10591.0234, KL Div: 3340.4768\n",
      "Epoch[14/15], Step [220/469], Reconst Loss: 10316.3750, KL Div: 3261.7419\n",
      "Epoch[14/15], Step [230/469], Reconst Loss: 9769.4277, KL Div: 3174.2361\n",
      "Epoch[14/15], Step [240/469], Reconst Loss: 10031.3730, KL Div: 3194.0652\n",
      "Epoch[14/15], Step [250/469], Reconst Loss: 9989.5791, KL Div: 3206.6638\n",
      "Epoch[14/15], Step [260/469], Reconst Loss: 10058.0645, KL Div: 3131.9541\n",
      "Epoch[14/15], Step [270/469], Reconst Loss: 10520.5352, KL Div: 3295.1250\n",
      "Epoch[14/15], Step [280/469], Reconst Loss: 10151.1406, KL Div: 3169.6562\n",
      "Epoch[14/15], Step [290/469], Reconst Loss: 10142.2402, KL Div: 3234.5664\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 10203.1475, KL Div: 3218.4624\n",
      "Epoch[14/15], Step [310/469], Reconst Loss: 10277.8535, KL Div: 3215.3821\n",
      "Epoch[14/15], Step [320/469], Reconst Loss: 10206.4629, KL Div: 3249.9272\n",
      "Epoch[14/15], Step [330/469], Reconst Loss: 9977.6006, KL Div: 3192.4316\n",
      "Epoch[14/15], Step [340/469], Reconst Loss: 10120.6260, KL Div: 3213.2134\n",
      "Epoch[14/15], Step [350/469], Reconst Loss: 10234.3691, KL Div: 3304.8242\n",
      "Epoch[14/15], Step [360/469], Reconst Loss: 9865.3213, KL Div: 3176.9114\n",
      "Epoch[14/15], Step [370/469], Reconst Loss: 9906.0957, KL Div: 3227.2446\n",
      "Epoch[14/15], Step [380/469], Reconst Loss: 10319.0254, KL Div: 3258.2275\n",
      "Epoch[14/15], Step [390/469], Reconst Loss: 9915.8984, KL Div: 3073.0862\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 10400.3857, KL Div: 3345.8647\n",
      "Epoch[14/15], Step [410/469], Reconst Loss: 10332.4736, KL Div: 3278.7661\n",
      "Epoch[14/15], Step [420/469], Reconst Loss: 10294.1621, KL Div: 3109.6003\n",
      "Epoch[14/15], Step [430/469], Reconst Loss: 10191.8340, KL Div: 3291.8445\n",
      "Epoch[14/15], Step [440/469], Reconst Loss: 10242.6074, KL Div: 3204.8765\n",
      "Epoch[14/15], Step [450/469], Reconst Loss: 10295.8164, KL Div: 3259.7905\n",
      "Epoch[14/15], Step [460/469], Reconst Loss: 10355.3145, KL Div: 3263.0986\n",
      "Epoch[15/15], Step [10/469], Reconst Loss: 9867.7490, KL Div: 3256.2078\n",
      "Epoch[15/15], Step [20/469], Reconst Loss: 10481.2812, KL Div: 3215.9580\n",
      "Epoch[15/15], Step [30/469], Reconst Loss: 10093.7695, KL Div: 3307.2422\n",
      "Epoch[15/15], Step [40/469], Reconst Loss: 10386.9639, KL Div: 3224.5540\n",
      "Epoch[15/15], Step [50/469], Reconst Loss: 10154.7598, KL Div: 3189.9861\n",
      "Epoch[15/15], Step [60/469], Reconst Loss: 10123.3057, KL Div: 3139.6096\n",
      "Epoch[15/15], Step [70/469], Reconst Loss: 9668.1963, KL Div: 3222.9287\n",
      "Epoch[15/15], Step [80/469], Reconst Loss: 10266.2803, KL Div: 3248.2510\n",
      "Epoch[15/15], Step [90/469], Reconst Loss: 9995.4727, KL Div: 3258.2998\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 9982.8877, KL Div: 3222.6277\n",
      "Epoch[15/15], Step [110/469], Reconst Loss: 10119.0820, KL Div: 3168.1724\n",
      "Epoch[15/15], Step [120/469], Reconst Loss: 9654.4111, KL Div: 3177.3730\n",
      "Epoch[15/15], Step [130/469], Reconst Loss: 10278.9131, KL Div: 3194.0039\n",
      "Epoch[15/15], Step [140/469], Reconst Loss: 10331.6787, KL Div: 3219.6377\n",
      "Epoch[15/15], Step [150/469], Reconst Loss: 10507.8232, KL Div: 3326.2654\n",
      "Epoch[15/15], Step [160/469], Reconst Loss: 9820.7686, KL Div: 3142.7739\n",
      "Epoch[15/15], Step [170/469], Reconst Loss: 10452.1953, KL Div: 3329.9006\n",
      "Epoch[15/15], Step [180/469], Reconst Loss: 10466.3301, KL Div: 3252.4844\n",
      "Epoch[15/15], Step [190/469], Reconst Loss: 9588.0312, KL Div: 3154.6245\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 10155.9863, KL Div: 3267.9546\n",
      "Epoch[15/15], Step [210/469], Reconst Loss: 10035.7109, KL Div: 3173.4136\n",
      "Epoch[15/15], Step [220/469], Reconst Loss: 10187.9775, KL Div: 3157.8687\n",
      "Epoch[15/15], Step [230/469], Reconst Loss: 10440.2773, KL Div: 3367.1509\n",
      "Epoch[15/15], Step [240/469], Reconst Loss: 10277.9658, KL Div: 3179.8328\n",
      "Epoch[15/15], Step [250/469], Reconst Loss: 9954.5723, KL Div: 3242.5959\n",
      "Epoch[15/15], Step [260/469], Reconst Loss: 10271.5547, KL Div: 3248.2573\n",
      "Epoch[15/15], Step [270/469], Reconst Loss: 10416.0762, KL Div: 3168.9468\n",
      "Epoch[15/15], Step [280/469], Reconst Loss: 9618.4492, KL Div: 3149.9429\n",
      "Epoch[15/15], Step [290/469], Reconst Loss: 9947.6406, KL Div: 3173.0046\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 9980.4219, KL Div: 3187.2183\n",
      "Epoch[15/15], Step [310/469], Reconst Loss: 9876.7168, KL Div: 3176.0081\n",
      "Epoch[15/15], Step [320/469], Reconst Loss: 10831.8438, KL Div: 3194.7993\n",
      "Epoch[15/15], Step [330/469], Reconst Loss: 10266.0391, KL Div: 3215.7710\n",
      "Epoch[15/15], Step [340/469], Reconst Loss: 10509.8330, KL Div: 3330.0842\n",
      "Epoch[15/15], Step [350/469], Reconst Loss: 9867.5127, KL Div: 3155.7791\n",
      "Epoch[15/15], Step [360/469], Reconst Loss: 10150.1973, KL Div: 3181.6072\n",
      "Epoch[15/15], Step [370/469], Reconst Loss: 10035.8496, KL Div: 3154.3645\n",
      "Epoch[15/15], Step [380/469], Reconst Loss: 10153.6240, KL Div: 3208.4275\n",
      "Epoch[15/15], Step [390/469], Reconst Loss: 10080.7939, KL Div: 3222.1860\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 10412.8428, KL Div: 3247.3936\n",
      "Epoch[15/15], Step [410/469], Reconst Loss: 10676.8320, KL Div: 3231.8689\n",
      "Epoch[15/15], Step [420/469], Reconst Loss: 10026.0195, KL Div: 3276.7883\n",
      "Epoch[15/15], Step [430/469], Reconst Loss: 10348.2383, KL Div: 3319.1133\n",
      "Epoch[15/15], Step [440/469], Reconst Loss: 10072.1377, KL Div: 3273.5024\n",
      "Epoch[15/15], Step [450/469], Reconst Loss: 10199.5078, KL Div: 3331.2827\n",
      "Epoch[15/15], Step [460/469], Reconst Loss: 9910.7891, KL Div: 3211.6675\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
